# DataFlow AI ‚Äì Pipeline intelligent, CLI avanc√©e & outils pour la pr√©paration, la transformation, la s√©curisation et l'enrichissement des donn√©es JSON & PDF pour l'IA et le RAG

![Version](https://img.shields.io/badge/version-1.0-blue) ![Python](https://img.shields.io/badge/Python-3.8%2B-green) ![License](https://img.shields.io/badge/license-MIT-orange)

> üá¨üáß [English version available here](README.md)
> üìö **Toute la documentation (FR/EN) est d√©sormais centralis√©e dans le dossier [`/documentation`](documentation/).**
> Vous y trouverez tous les guides (CLI, Extract, LLM, Outlines, S√©curit√©, API, Frontend) en fran√ßais et en anglais dans les sous-dossiers correspondants.

## üìë Sommaire

- [Introduction](#-introduction)
- [Vue d'ensemble](#-vue-densemble)
- [Guide de r√©f√©rence rapide](#-guide-de-r√©f√©rence-rapide)
- [Fonctionnalit√©s principales](#-fonctionnalit√©s-principales)
- [Installation](#Ô∏è-installation)
- [Guide d'utilisation rapide](#-guide-dutilisation-rapide)
- [Organisation des r√©sultats](#-organisation-des-r√©sultats)
- [R√©sum√©s LLM automatiques](#-r√©sum√©s-llm-automatiques)
- [Approche flexible et g√©n√©rique](#-approche-flexible-et-g√©n√©rique)
- [Syst√®me de fallback robuste](#-syst√®me-de-fallback-robuste)
- [Utilitaires](#Ô∏è-utilitaires)
- [Extension du syst√®me](#-extension-du-syst√®me)
- [Int√©gration avec Temporal et Llamendex](#-int√©gration-avec-temporal-et-llamendex)
- [Format pour Llamendex](#-format-pour-llamendex)
- [Analyse de documents PDF](#-analyse-de-documents-pdf)
- [API](#-api)
- [Frontend](#-frontend)
- [S√©curit√©](#-s√©curit√©)
- [D√©pendances](#Ô∏è-d√©pendances)
- [Licence](#-licence)

## üîç Introduction

Ce projet est une solution compl√®te pour traiter, analyser et transformer des fichiers JSON et des documents PDF provenant de diff√©rentes sources (JIRA, Confluence, GitHub, etc.) en pr√©paration pour l'indexation dans Llamendex ou tout autre syst√®me RAG moderne.

La particularit√© de cette solution r√©side dans sa capacit√© √† **s'adapter automatiquement √† n'importe quelle structure JSON et extraire intelligemment le contenu des PDF** et √† garantir un traitement robuste des fichiers, m√™me en pr√©sence d'erreurs ou d'incoh√©rences. Contrairement aux outils g√©n√©riques de traitement JSON, notre solution allie:

- **D√©tection intelligente** de la structure des donn√©es
- **Pr√©servation des fichiers sources** (jamais modifi√©s directement)
- **Enrichissement s√©mantique par LLM** avec Outlines
- **Extraction intelligente de PDF** (texte natif + images analys√©es par IA)
- **Rapports d√©taill√©s** g√©n√©r√©s automatiquement
- **Correction automatique** des erreurs de syntaxe JSON
- **Interface CLI interactive** et accessible

> üí° **NOUVEAU!** Int√©gration compl√®te des outils de s√©curit√© et de nettoyage des donn√©es sensibles directement dans l'interface CLI et dans les processeurs JSON.
> üí° **NOUVEAU!** Traitement avanc√© des PDF avec extraction intelligente du texte et analyse des images par IA gr√¢ce √† GPT-4o.

### Pourquoi cette solution ?

Dans le d√©veloppement de syst√®mes RAG (Retrieval Augmented Generation) comme Llamendex, l'ingestion de donn√©es de qualit√© est cruciale. Pourtant, nous faisons face √† plusieurs d√©fis concrets :

1. **H√©t√©rog√©n√©it√© des sources** : Chaque syst√®me (JIRA, Confluence, GitHub) exporte des structures JSON diff√©rentes
2. **Fichiers mal form√©s** : Les exports contiennent souvent des erreurs syntaxiques ou structurelles
3. **Volumes importants** : Les exports peuvent atteindre plusieurs gigaoctets, d√©passant les capacit√©s de traitement standard
4. **Perte de contexte** : L'enrichissement manuel des donn√©es est chronophage et inconsistant
5. **Complexit√© des PDF** : Les extracteurs standards perdent la structure ou convertissent tout en images
6. **Absence de correspondances** : Les liens entre tickets JIRA et pages Confluence sont souvent perdus

Notre solution r√©pond √† ces d√©fis en proposant un pipeline complet et robuste qui :
- D√©tecte et r√©pare automatiquement les probl√®mes de structure
- Standardise les donn√©es dans un format optimal pour les syst√®mes RAG
- Enrichit le contenu gr√¢ce √† des LLM pour am√©liorer la recherche s√©mantique
- Extrait intelligemment le texte et les images des PDF avec analyse IA
- √âtablit des correspondances entre diff√©rentes sources de donn√©es
- G√©n√®re automatiquement des r√©sum√©s et analyses pour faciliter l'ingestion

De plus, contrairement aux outils ETL g√©n√©riques ou aux solutions de traitement tabulaire comme pandas, notre solution est sp√©cifiquement con√ßue pour pr√©parer des donn√©es textuelles riches pour les syst√®mes de RAG, avec une attention particuli√®re √† la pr√©servation du contexte et √† l'enrichissement s√©mantique.

## üéØ Vue d'ensemble

Le projet se compose de trois modules principaux :
- **CLI** : Interface en ligne de commande interactive et puissante pour toutes les op√©rations
- **Extract** : Moteur de traitement flexible pour l'analyse et la transformation des donn√©es
- **Tools** : Utilitaires pour r√©soudre des probl√®mes sp√©cifiques (nettoyage, validation)

<!-- D√âBUT ENCART DE R√âF√âRENCE RAPIDE -->
<div align="center">

## üìã Guide de r√©f√©rence rapide

</div>

| Commande | Description | Exemple |
|---------|-------------|---------|
| `interactive` | **Mode interactif** avec assistant guid√© | `python -m cli.cli interactive` |
| `process` | **Traiter** un fichier JSON | `python -m cli.cli process fichier.json --llm` |
| `chunks` | **D√©couper** un fichier volumineux | `python -m cli.cli chunks gros_fichier.json --items-per-file 500` |
| `match` | **Correspondances** JIRA-Confluence | `python -m cli.cli match jira.json confluence.json` |
| `unified` | **Flux complet** de traitement | `python -m cli.cli unified jira1.json jira2.json --confluence conf1.json` |
| `extract-images` | **Extraire & analyser** le contenu PDF | `python -m cli.cli extract-images complete fichier.pdf --max-images 10` |
| `clean` | **Nettoyer** les donn√©es sensibles | `python -m cli.cli clean fichier.json --recursive` |
| `compress` | **Compresser & optimiser** des fichiers JSON | `python -m cli.cli compress repertoire --level 19` |

<div align="center">

### üõ†Ô∏è Outils ind√©pendants

</div>

| Outil | Description | Exemple |
|-------|-------------|---------|
| `check_json.py` | **V√©rifier** la validit√© des fichiers JSON | `python -m tools.check_json fichier.json` |
| `clean_sensitive_data.py` | **Nettoyer** les donn√©es sensibles | `python -m tools.clean_sensitive_data fichier.json` |
| `fix_paths.py` | **R√©parer** les chemins et les fichiers | `python -m tools.fix_paths --all --source-dir=files` |

<!-- FIN ENCART DE R√âF√âRENCE RAPIDE -->

## üéØ Fonctionnalit√©s principales

- **D√©tection automatique** de type de fichier (JIRA, Confluence, GitHub)
- **Transformation flexible** via des mappings personnalisables
- **Mode interactif complet** avec assistant guid√© pour toutes les op√©rations
- **D√©coupage et traitement** de fichiers volumineux
- **Extraction de m√©tadonn√©es** structur√©es
- **√âtablissement de correspondances** entre diff√©rentes sources
- **Extraction structur√©e avec Outlines** pour une g√©n√©ration contrainte par sch√©ma
- **Enrichissement par LLM** (OpenAI) pour l'analyse s√©mantique
- **Arborescences d√©taill√©es** du contenu de chaque fichier trait√©
- **Organisation automatique** des r√©sultats avec timestamps uniques
- **R√©sum√©s LLM g√©n√©r√©s automatiquement** pour chaque traitement
- **Gestion robuste des erreurs** avec diff√©rents niveaux de fallback

## ‚öôÔ∏è Installation

1. Clonez ce d√©p√¥t et acc√©dez au dossier
2. Cr√©ez un fichier `.env` en copiant `.env.example`
3. Installez les d√©pendances :

```bash
pip install -r requirements.txt
```

### ‚ö†Ô∏è Exigences Python pour Outlines

**IMPORTANT**: Outlines 0.2.3 requiert **Python 3.12** sp√©cifiquement. Il est fortement recommand√© de cr√©er un environnement virtuel d√©di√©:

```bash
# Cr√©er un environnement virtuel avec Python 3.12
python3.12 -m venv venv_outlines

# Activer l'environnement
source venv_outlines/bin/activate  # Linux/Mac
venv_outlines\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

Les versions plus r√©centes de Python (3.13+) ne sont pas compatibles avec Outlines 0.2.3, et les fonctionnalit√©s LLM ne fonctionneront pas correctement sans cet environnement sp√©cifique.

### Configuration d'Outlines (optionnelle)

Le syst√®me utilise la biblioth√®que [Outlines](https://github.com/dottxt/outlines) (v0.2.3) pour l'extraction structur√©e de donn√©es. Deux modes de fonctionnement sont disponibles :

1. **Mode complet** : Avec la biblioth√®que Outlines install√©e et une cl√© API OpenAI
2. **Mode stub** : Fonctionnement d√©grad√© sans Outlines ou sans cl√© API

Le syst√®me d√©tecte automatiquement la configuration disponible et s'adapte en cons√©quence. Pour v√©rifier votre installation :

```bash
python -m tests.test_outlines_integration
```

## üìñ Guide d'utilisation rapide

<div class="command-box">

### üîç Mode interactif (recommand√©)

Lancez l'assistant complet qui vous guide √©tape par √©tape :

```bash
python -m cli.cli interactive
```

</div>

<div class="command-box">

### üìÑ Traitement de fichiers JSON

```bash
python -m cli.cli process mon_fichier.json --output resultat.json
```

#### Avec enrichissement LLM et pr√©servation des sources

```bash
python -m cli.cli process mon_fichier.json --llm --preserve-source
```

</div>

<div class="command-box">

### üî™ D√©coupage de fichiers volumineux

```bash
python -m cli.cli chunks mon_gros_fichier.json --output-dir dossier_morceaux --items-per-file 500
```

</div>

<div class="command-box">

### üîó Correspondances entre JIRA et Confluence

```bash
python -m cli.cli match jira_processed.json confluence_processed.json --output-dir resultats_match
```

</div>

<div class="command-box">

### üöÄ Flux de traitement complet

```bash
python -m cli.cli unified jira1.json jira2.json --confluence conf1.json conf2.json --output-dir resultats_complets
```

</div>

<div class="command-box">

### üßπ Nettoyage des donn√©es sensibles

```bash
python -m cli.cli clean fichier.json --output fichier_propre.json
```

</div>

<div class="command-box">

### üì¶ Compression et optimisation des fichiers JSON

```bash
# Compresser un r√©pertoire sp√©cifique de fichiers JSON
python -m cli.cli compress results/mes_donnees --level 19 --keep-originals

# Compression avec le traitement unifi√©
python -m cli.cli unified jira1.json --output-dir dossier_resultats --compress
```

Le syst√®me de compression utilise orjson et zstd pour obtenir des √©conomies d'espace consid√©rables (jusqu'√† 90%) tout en pr√©servant l'int√©grit√© des donn√©es.

</div>

<div class="command-box">

### üìÑ Extraction de texte et d'images PDF

```bash
# Extraire le texte et analyser les images d'un fichier PDF
python -m cli.cli extract-images complete chemin/vers/fichier.pdf --max-images 10

# Sauvegarder le contenu extrait dans un r√©pertoire sp√©cifique
python -m cli.cli extract-images complete chemin/vers/fichier.pdf --output-dir analyse_pdf
```

</div>

## üìä Organisation des r√©sultats

Tous les r√©sultats sont organis√©s dans le dossier `results/` avec une structure claire :

```
results/
‚îú‚îÄ‚îÄ demo_test/                             # Exemple de dossier de notre dernier test
‚îÇ   ‚îú‚îÄ‚îÄ jira/                               # Sous-dossier pour les fichiers JIRA
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ demo_NEXUS_jira_processed.json  # Fichier JIRA trait√©
‚îÇ   ‚îú‚îÄ‚îÄ confluence/                         # Sous-dossier pour les fichiers Confluence
‚îÇ   ‚îú‚îÄ‚îÄ matches/                            # Sous-dossier pour les correspondances
‚îÇ   ‚îú‚îÄ‚îÄ split_jira_files/                   # Fichiers JIRA d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ split_confluence_files/             # Fichiers Confluence d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ llm_ready/                          # Fichiers pr√™ts pour LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_jira.json              # JIRA enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_jira.json.zst          # Version compress√©e (si activ√©e)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_confluence.json        # Confluence enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_confluence.json.zst    # Version compress√©e (si activ√©e)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jira_llm_enrichment_summary.md  # R√©sum√© LLM pour JIRA
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ confluence_llm_enrichment_summary.md # R√©sum√© LLM pour Confluence
‚îÇ   ‚îú‚îÄ‚îÄ compression_report_fr.txt           # Statistiques de compression (si activ√©e)
‚îÇ   ‚îú‚îÄ‚îÄ global_arborescence.txt             # Arborescence globale
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

## üß† R√©sum√©s LLM automatiques

> üìù **Fonctionnalit√© avanc√©e**: Pour chaque traitement utilisant un LLM, un rapport de r√©sum√© est automatiquement g√©n√©r√© au format Markdown.

> üí° **NOUVEAU!** Notre module `outlines_enricher.py` enrichit d√©sormais chaque √©l√©ment JSON (tickets JIRA/pages Confluence) avec des analyses LLM avanc√©es. Pour chaque √©l√©ment, il extrait le contenu textuel (titre, description, commentaires), l'envoie √† l'API OpenAI (GPT-4-0125-preview), et r√©cup√®re une analyse structur√©e contenant: un r√©sum√© concis (150 mots max), 5-10 mots-cl√©s importants, les entit√©s identifi√©es (personnes, organisations, termes techniques) et le sentiment g√©n√©ral. Ces donn√©es sont ajout√©es sous la cl√© `analysis` avec les sous-champs `llm_summary`, `llm_keywords`, `llm_entities` et `llm_sentiment`. Le module adapte automatiquement diff√©rentes structures JSON pour assurer une liste `items` correcte avant traitement.

Exemple de r√©sum√© g√©n√©r√©:

<details>
<summary>üëâ Voir un exemple de r√©sum√© LLM (cliquez pour d√©velopper)</summary>

```markdown
# R√©sum√© de l'enrichissement LLM

## Informations g√©n√©rales
- Date d'analyse: 2023-05-08 23:34:37
- Nombre total d'√©l√©ments analys√©s: 42
- Mod√®le LLM utilis√©: gpt-4

## Analyse
### Mots-cl√©s principaux extraits
projet, d√©veloppement, API, backend, utilisateur, interface, base de donn√©es

### Distribution des sentiments
{'positive': 12, 'neutral': 25, 'negative': 5}

### Exemple d'enrichissement
**Ticket**: NEXUS-123 - Impl√©mentation de l'authentification OAuth2
**R√©sum√© LLM**: Ce ticket concerne l'int√©gration du protocole OAuth2 pour s√©curiser l'API. L'impl√©mentation comprend l'enregistrement des clients, la gestion des tokens et la gestion des p√©rim√®tres d'acc√®s. L'√©quipe a not√© des d√©fis avec la persistance des tokens de rafra√Æchissement, mais les a r√©solus gr√¢ce √† une table de base de donn√©es d√©di√©e. Les tests montrent une int√©gration r√©ussie avec l'application frontend. Pr√™t pour r√©vision par l'√©quipe de s√©curit√© avant le d√©ploiement final en production.
**Mots-cl√©s**: OAuth2, authentification, s√©curit√© API, tokens, enregistrement client
**Entit√©s**: Jean Dupont (d√©veloppeur), √âquipe de S√©curit√©, protocole OAuth2, JWT
**Sentiment**: Positif
```

</details>

Ces r√©sum√©s permettent:
1. Une vue d'ensemble rapide du contenu trait√©
2. L'extraction des principaux th√®mes et sentiments
3. Des exemples concrets d'enrichissement LLM
4. Une pr√©paration optimale pour l'ingestion dans Llamendex

## üîç Approche flexible et g√©n√©rique

L'approche adopt√©e permet de traiter n'importe quelle structure JSON, gr√¢ce √† :

1. **D√©tection automatique de structure** : Analyse des champs importants
2. **Mappers personnalisables** : Adaptation √† n'importe quel format
3. **Traitement par morceaux** : Gestion efficace de fichiers volumineux
4. **Transformation flexible** : Structure de sortie adaptable
5. **Pr√©servation des sources** : Travail uniquement sur des copies

## üí° Syst√®me de fallback robuste

Notre solution est con√ßue pour fonctionner dans diff√©rents environnements, gr√¢ce √† un syst√®me de fallback √† plusieurs niveaux :

| Niveau | Configuration | Fonctionnalit√©s |
|--------|--------------|-----------------|
| **1** | Outlines + OpenAI | Extraction structur√©e compl√®te, r√©paration automatique |
| **2** | Sans OpenAI | Mode d√©grad√© d'Outlines, certaines fonctionnalit√©s d√©sactiv√©es |
| **3** | Sans Outlines | Utilisation de stubs internes imitant l'API d'Outlines |
| **4** | Fallback standard | Parseur JSON standard en dernier recours |

Cette architecture garantit que le syst√®me reste op√©rationnel m√™me sans connexion internet ou cl√© API.

## üîÑ Traitement JSON robuste

Le syst√®me inclut des capacit√©s avanc√©es de traitement JSON pour g√©rer les fichiers JSON malform√©s ou invalides :

- **Parsing robuste** : Multiples m√©canismes de fallback pour g√©rer les fichiers JSON malform√©s
- **R√©paration intelligente** : Capacit√© √† r√©cup√©rer des erreurs de format JSON courantes
- **R√©paration assist√©e par LLM** : Utilisation optionnelle de LLM pour corriger des probl√®mes structurels complexes
- **Parsing progressif** : Peut traiter des fichiers extr√™mement volumineux en les lisant par morceaux
- **Tol√©rance aux pannes** : Le syst√®me continue le traitement m√™me si certains fichiers contiennent des erreurs

Dans nos derniers tests, le syst√®me a trait√© avec succ√®s les fichiers de d√©monstration du projet NEXUS qui contenaient plusieurs incoh√©rences de formatage, sans n√©cessiter d'intervention manuelle.

## üõ†Ô∏è Utilitaires

Le projet inclut des outils pratiques dans le dossier `tools/` :

1. **check_json.py** : V√©rifier la validit√© des fichiers JSON
   ```bash
   python -m tools.check_json chemin/vers/fichier.json
   ```

2. **fix_paths.py** : Corriger les probl√®mes de chemins et r√©parer les fichiers JSON
   ```bash
   python -m tools.fix_paths --all --source-dir=files --target-dir=results/fixed
   ```

3. **clean_sensitive_data.py** : Nettoyer les donn√©es sensibles (cl√©s API, emails, etc.)
   ```bash
   python -m tools.clean_sensitive_data fichier.json --output fichier_clean.json
   ```

4. **compress_utils.py** : Compresser et optimiser les fichiers JSON avec zstd et orjson
   ```bash
   python -m extract.compress_utils --directory results/mes_donnees --level 19
   ```

### Utilisation des outils dans le CLI

Les outils sont int√©gr√©s au CLI principal et peuvent √™tre utilis√©s de mani√®re interactive :

```bash
# Lancer le nettoyage des donn√©es sensibles via le CLI
python -m cli.cli clean fichier.json --output fichier_clean.json

# Compresser des fichiers JSON via le CLI
python -m cli.cli compress results/mes_donnees --level 19

# Utiliser le mode interactif
python -m cli.cli interactive
# Puis s√©lectionner "Nettoyer les donn√©es sensibles (clean)" ou "Compresser et optimiser des fichiers JSON"
```

### Int√©gration programmatique

Les outils peuvent √©galement √™tre import√©s et utilis√©s directement dans votre code :

```python
# V√©rifier la validit√© d'un fichier JSON
from tools import validate_file
is_valid, error_msg = validate_file("mon_fichier.json")
if not is_valid:
    print(f"Erreur dans le fichier: {error_msg}")

# Nettoyer les donn√©es sensibles
from tools import clean_json_file
clean_json_file("fichier_avec_api_keys.json", "fichier_securise.json")

# Corriger les chemins dupliqu√©s
from tools import fix_duplicate_paths
fix_duplicate_paths("dossier_r√©sultats")
```

Le traitement principal via `GenericJsonProcessor` int√®gre automatiquement ces outils pour v√©rifier la validit√© des fichiers JSON et nettoyer les donn√©es sensibles avant sauvegarde.

## üß© Extension du syst√®me

### Cr√©er vos propres mappers

Pour adapter la solution √† de nouvelles sources :

```python
from extract.generic_json_processor import GenericJsonProcessor

def mon_mapper_personnalise(item):
    # Transformer l'item selon vos besoins
    result = {
        "id": item.get("identifiant", ""),
        "content": {
            "title": item.get("nom", ""),
            "body": item.get("contenu", "")
        },
        "metadata": {
            "created_at": item.get("date_creation", ""),
            "type": item.get("type", "")
        }
    }
    return result

# Cr√©er le processeur avec votre mapper
processor = GenericJsonProcessor(custom_mapper=mon_mapper_personnalise)
processor.process_file("mon_fichier.json", "resultat.json")
```

### Utiliser Outlines pour l'extraction structur√©e

```python
from extract.outlines_enhanced_parser import outlines_robust_json_parser
from extract.outlines_extractor import extract_structured_data

# Parser un fichier JSON avec Outlines
data = outlines_robust_json_parser("mon_fichier.json", llm_fallback=True)

# Extraire des donn√©es structur√©es selon un sch√©ma
schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "categories": {
            "type": "array",
            "items": {"type": "string"}
        }
    }
}
result = extract_structured_data(text_content, schema)
```

## üîÑ Int√©gration avec Temporal et Llamendex

Notre solution s'int√®gre parfaitement avec des workflows Temporal et Llamendex :

| **Workflow Temporal** | **Index associ√©** | **Notre solution** |
|------------------------|-------------------|---------------------|
| `SyncJiraAndIndex` | `JiraIndex` | Utilise notre processeur avec mapping JIRA |
| `SyncConfluenceAndIndex` | `ConfluenceIndex` | Utilise notre processeur avec mapping Confluence |
| `HandleUserQueryToAgent` | (tous) | Interroge les donn√©es transform√©es par notre solution |

## üìù Format pour Llamendex

La structure de sortie est optimis√©e pour Llamendex, permettant une conversion directe en `NodeWithScore` :

```json
{
  "items": [
    {
      "id": "IDENTIFIANT",
      "title": "TITRE",
      "content": {
        "field1": "CONTENU1",
        "field2": "CONTENU2"
      },
      "metadata": {
        "created_at": "DATE",
        "author": "AUTEUR"
      },
      "analysis": {
        "llm_summary": "R√©sum√© concis g√©n√©r√© par LLM",
        "llm_keywords": ["MOT1", "MOT2"],
        "llm_entities": {
          "people": ["PERSONNE1", "PERSONNE2"],
          "organizations": ["ORG1", "ORG2"]
        },
        "llm_sentiment": "positive"
      },
      "relationships": {
        "confluence_links": [],
        "jira_tickets": []
      }
    }
  ],
  "metadata": {
    "source_file": "fichier_source.json",
    "processed_at": "DATE_TRAITEMENT",
    "llm_enrichment": {
      "model": "gpt-4o",
      "enrichment_date": "DATE_ENRICHISSEMENT"
    }
  }
}
```

## üìÑ Analyse de documents PDF

> üîç **NOUVEAU!** Le syst√®me inclut d√©sormais un extracteur PDF intelligent qui combine extraction native de texte et analyse IA des images.

### Fonctionnalit√©s de l'extracteur PDF

L'Extracteur PDF Complet est un module sp√©cialis√© con√ßu pour extraire et analyser intelligemment le contenu des documents PDF. Contrairement aux extracteurs PDF traditionnels, ce module:

1. **Extrait nativement** le texte brut du PDF, pr√©servant sa structure originale
2. **D√©tecte et extrait** uniquement les images int√©gr√©es dans le document
3. **Analyse avec IA** exclusivement les images pour une compr√©hension enrichie 
4. **G√©n√®re un JSON unifi√©** combinant le texte extrait et les analyses d'images

Cette approche cibl√©e √©vite de transformer toutes les pages en images, ce qui pr√©serve la qualit√© du texte natif tout en permettant une compr√©hension am√©lior√©e par IA des √©l√©ments visuels.

### Utilisation via CLI

```bash
# Mode interactif
python -m cli.cli interactive
# Puis s√©lectionner "Extraction compl√®te d'un PDF (texte + images analys√©es)"

# OU commande directe
python -m cli.cli extract-images complete chemin/vers/fichier.pdf --max-images 10
```

### Structure du JSON unifi√©

Pour chaque PDF trait√©, vous obtiendrez un JSON structur√© contenant:

- M√©tadonn√©es du document (nom, timestamp, langue)
- Texte brut de chaque page
- √âl√©ments structur√©s par page (texte et images)
- Descriptions IA pour chaque image avec contexte
- Statistiques g√©n√©rales (pages, images d√©tect√©es, images analys√©es)

### Exemples d'applications

- **Analyse de documents techniques**: Extraction du contenu textuel avec enrichissement IA des diagrammes et figures
- **Documentation juridique**: Pr√©servation de la structure exacte du texte avec analyse des signatures et tampons
- **Rapports financiers**: Extraction des donn√©es textuelles avec compr√©hension IA des graphiques et tableaux
- **Publications scientifiques**: Conservation du texte structur√© avec analyse des formules et illustrations

### Documentation compl√®te

Une documentation d√©taill√©e est disponible dans le dossier [`/documentation/pdf/`](documentation/pdf/) avec:

- Guide d'utilisation complet en fran√ßais et anglais
- Exemples de commandes avanc√©es
- Description d√©taill√©e de la structure de sortie
- Guide de d√©pannage

## üöÄ API

DataFlow AI inclut une API RESTful robuste construite avec FastAPI qui fournit un acc√®s programmatique √† toutes les fonctionnalit√©s de traitement et d'analyse de donn√©es.

### Fonctionnalit√©s cl√©s de l'API

- **Architecture RESTful** - M√©thodes HTTP standards avec r√©ponses JSON coh√©rentes
- **Documentation interactive** - Interface Swagger g√©n√©r√©e automatiquement √† `/docs`
- **Endpoints flexibles** - Acc√®s complet √† toutes les fonctionnalit√©s de traitement
- **T√©l√©versements s√©curis√©s** - Validation des fichiers et stockage temporaire s√©curis√©
- **Support Cross-Origin** - CORS configur√© pour les applications web
- **Traitement asynchrone** - Op√©rations non bloquantes pour de meilleures performances

### Endpoints principaux

- **Traitement PDF** - Extraction de texte et analyse d'images des documents PDF
- **Traitement JSON** - Nettoyage, compression et transformation des donn√©es JSON
- **Traitement unifi√©** - Traitement et correspondance des donn√©es JIRA et Confluence

Pour la documentation compl√®te, consultez le dossier [Documentation API](documentation/api/).

## üíª Frontend

DataFlow AI inclut une interface web moderne construite avec React et TypeScript qui fournit un moyen convivial d'acc√©der √† toutes les fonctionnalit√©s du syst√®me.

### Fonctionnalit√©s du Frontend

- **Interface moderne** - Interface propre et responsive utilisant React et Tailwind CSS
- **Multilingue** - Support complet pour le fran√ßais et l'anglais
- **Modes clair/sombre** - Personnalisation du th√®me selon les pr√©f√©rences de l'utilisateur
- **Glisser-d√©poser** - T√©l√©versement et traitement intuitifs des fichiers
- **Workflow interactif** - Guidage √©tape par √©tape √† travers les options de traitement
- **Visualisation des r√©sultats** - Pr√©sentation claire des r√©sultats de traitement

### √âcrans principaux

- **Analyse PDF** - T√©l√©versement et traitement de documents PDF avec analyse d'images par IA
- **Traitement JSON** - Nettoyage, compression et d√©coupage de fichiers JSON
- **Traitement unifi√©** - Correspondance et traitement des donn√©es JIRA et Confluence

Pour la documentation compl√®te, consultez le dossier [Documentation Frontend](documentation/frontend/).

## üîí S√©curit√©

### Bonnes pratiques de s√©curit√©

Ce projet inclut des mesures de protection pour √©viter la fuite de donn√©es sensibles :

#### üö´ Ne jamais commiter de donn√©es sensibles
- **Cl√©s API** (AWS, OpenAI, etc.)
- **Informations personnelles** (emails, noms, etc.)
- **Donn√©es de test r√©elles**
- **Tokens d'authentification**
- **Identifiants de connexion**

#### ‚úÖ Manipulation des donn√©es sensibles
1. **Variables d'environnement** : Toujours stocker les cl√©s API dans le fichier `.env` (jamais dans le code)
2. **Donn√©es de test** : Utiliser uniquement des donn√©es synth√©tiques ou anonymis√©es
3. **Protection du Git** : Un hook pre-commit d√©tecte automatiquement les fuites potentielles

#### üßπ Nettoyage des donn√©es sensibles
Le projet inclut un outil pour nettoyer les fichiers de test :

```bash
# Nettoyer un fichier sp√©cifique
python -m tools.clean_sensitive_data path/to/file.json

# Nettoyer un dossier
python -m tools.clean_sensitive_data path/to/directory --output path/to/output
```

#### üö® En cas de fuite
1. **√âliminer** la donn√©e sensible de l'historique Git
   ```bash
   git filter-branch --force --index-filter "git rm --cached --ignore-unmatch path/to/file" --prune-empty --tag-name-filter cat -- --all
   git push origin --force
   ```
2. **Invalider** les cl√©s ou tokens compromis
3. **Informer** les personnes concern√©es

Pour plus de d√©tails, consultez le fichier [SECURITY.md](SECURITY.md).

## ‚ö†Ô∏è D√©pendances

- Python 3.8+
- typer, rich, inquirer, python-dotenv, ijson
- openai (optionnel, pour les fonctionnalit√©s LLM)
- outlines==0.2.3 (optionnel, pour l'extraction structur√©e)
- zstandard, orjson (optionnel, pour la compression et l'optimisation JSON)

## üìú Licence

Ce projet est distribu√© sous licence MIT. 