# JSON Processor - Solution g√©n√©rique pour l'analyse et la transformation

## üéØ Objectif principal

Cette solution a √©t√© con√ßue pour structurer et unifier des sources de donn√©es diverses (JIRA, Confluence, Google Drive, Git) pour un syst√®me RAG avanc√© avec **Llamendex**. Chaque source suit un pipeline commun, mais avec une logique d'adaptation sp√©cifique pour maximiser la qualit√© de l'indexation s√©mantique et structurelle.

**Le but concret :**
- Extraire les m√©tadonn√©es structur√©es de diff√©rents formats JSON
- Cr√©er un arbre hi√©rarchique bien typ√© pour chaque source
- √âtablir des correspondances (matching) entre les diff√©rentes sources (JIRA ‚Üî Confluence ‚Üî Drive ‚Üî Git)
- Pr√©parer les donn√©es au format `NodeWithScore` pour Llamendex, incluant le graphe de relations

## üìÇ Contenu du dossier `extract`

Voici les principaux fichiers et leur fonction :

### Script principal g√©n√©rique
- `generic_json_processor.py` : Solution universelle pour traiter n'importe quel JSON

### Scripts sp√©cialis√©s
- **JIRA** :
  - `extract_jira_structure.py` : Extraction et analyse de structure
  - `transform_for_llm.py` : Transformation de donn√©es sp√©cifiques √† JIRA
  - `analyze_jira_export.py` : Analyse des exports JIRA

- **Confluence** :
  - `extract_confluence_structure.py` : Extraction et transformation de pages Confluence

### Utilitaires
- `process_by_chunks.py` : Gestion de fichiers JSON volumineux
- `match_jira_confluence.py` : Mise en correspondance JIRA-Confluence
- `run_analysis.py` : Orchestration du flux pour JIRA uniquement
- `run_unified_analysis.py` : Orchestration du flux complet JIRA + Confluence

## üîç Approche g√©n√©rique

L'approche adopt√©e ici permet de traiter n'importe quelle structure JSON, gr√¢ce √† :

1. **D√©tection automatique de structure** : Analyse et d√©tection des champs importants
2. **Mappers personnalisables** : Adaptation √† n'importe quel format d'entr√©e
3. **Traitement par morceaux** : Gestion efficace de fichiers volumineux
4. **Transformation flexible** : Structure de sortie adaptable selon les besoins

## üìñ Guide d'utilisation pratique

Voici comment utiliser concr√®tement cette solution pour vos fichiers JIRA et Confluence.

### 1. Traitement basique

```bash
python generic_json_processor.py --input mon_fichier.json --output resultat.json
```

### 2. Avec un mapping personnalis√©

Cr√©ez un fichier JSON de mapping (ex: `mapping.json`):
```json
{
  "id": "key",
  "title": ["title", "name", "subject"],
  "content": {
    "field": "description",
    "transform": "clean_text"
  },
  "keywords": {
    "field": "description",
    "transform": "extract_keywords"
  }
}
```

Puis utilisez-le:
```bash
python generic_json_processor.py --input mon_fichier.json --output resultat.json --mapping-file mapping.json
```

### 3. Pour les fichiers volumineux

```bash
python process_by_chunks.py split --input gros_fichier.json --output-dir dossier_morceaux --items-per-file 500
```

Puis traitez chaque morceau:
```bash
for fichier in dossier_morceaux/*.json; do
  python generic_json_processor.py --input "$fichier" --output "$(basename "$fichier" .json)_processed.json"
done
```

### 4. Traitement de plusieurs fichiers d'une m√™me source

Vous pouvez traiter plusieurs fichiers JIRA ou Confluence s√©quentiellement :

```bash
# Plusieurs fichiers JIRA
for file in jira_*.json; do
  output="${file%.json}_processed.json"
  python generic_json_processor.py --input "$file" --output "$output" --mapping-file mapping_examples/jira_mapping.json
done

# Plusieurs fichiers Confluence
for file in confluence_*.json; do
  output="${file%.json}_processed.json"
  python generic_json_processor.py --input "$file" --output "$output" --mapping-file mapping_examples/confluence_mapping.json
done
```

### 5. Workflow complet JIRA + Confluence

Pour traiter plusieurs fichiers JIRA et Confluence en m√™me temps et √©tablir des correspondances :

```bash
python run_unified_analysis.py --jira-files jira1.json jira2.json --confluence-files confluence1.json confluence2.json --output-dir resultats
```

Cette commande :
- Traite tous les fichiers JIRA sp√©cifi√©s
- Traite tous les fichiers Confluence sp√©cifi√©s
- √âtablit des correspondances entre eux
- Sauvegarde tous les r√©sultats dans le dossier `resultats`

### 6. √âtablir des correspondances apr√®s traitement individuel

Si vous avez d√©j√† trait√© vos fichiers s√©par√©ment :

```bash
python match_jira_confluence.py --jira jira_processed.json --confluence confluence_processed.json --output matches.json --updated-jira jira_with_matches.json --updated-confluence confluence_with_matches.json
```

### 7. Sc√©narios d'utilisation courants

#### Sc√©nario 1 : Extraction et analyse d'un export JIRA

```bash
# √âtape 1: Extraction de la structure
python extract_jira_structure.py mon_export_jira.json

# √âtape 2: Transformation pour LLM
python transform_for_llm.py --files mon_export_jira.json --output jira_llm_ready.json

# √âtape 3 (optionnel): Analyse avec OpenAI
python analyze_jira_export.py --api-key VOTRE_CLE_API
```

#### Sc√©nario 2 : Int√©grer un nouveau type de donn√©es

```bash
# √âtape 1: Cr√©er un fichier de mapping pour la nouvelle source
echo '{
  "id": "issueId", 
  "title": "summary",
  "content": {"field": "description", "transform": "clean_text"},
  "metadata": {
    "created_by": "authorName",
    "created_at": "creationDate"
  }
}' > nouveau_systeme_mapping.json

# √âtape 2: Traiter le fichier avec ce mapping
python generic_json_processor.py --input nouveau_systeme.json --output nouveau_traite.json --mapping-file nouveau_systeme_mapping.json
```

## üìä Structure des r√©sultats g√©n√©r√©s

Apr√®s traitement, votre dossier de r√©sultats contiendra :

- **Fichiers de structure d√©tect√©e** :
  - `jira_structure.json` : Structure d√©tect√©e des fichiers JIRA
  - `confluence_structure.json` : Structure d√©tect√©e des fichiers Confluence

- **Donn√©es transform√©es pour Llamendex** :
  - `llm_ready_jira.json` : Donn√©es JIRA transform√©es
  - `llm_ready_confluence.json` : Donn√©es Confluence transform√©es

- **Correspondances et relations** :
  - `jira_confluence_matches.json` : Correspondances d√©tect√©es
  - `jira_with_matches.json` : Donn√©es JIRA enrichies avec liens
  - `confluence_with_matches.json` : Donn√©es Confluence enrichies avec liens

## üß© Extension du syst√®me

### Cr√©er vos propres mappers

Pour adapter la solution √† de nouvelles sources :

```python
from generic_json_processor import GenericJsonProcessor

def mon_mapper_personnalise(item):
    # Transformer l'item selon vos besoins
    result = {
        "id": item.get("identifiant", ""),
        "content": {
            "title": item.get("nom", ""),
            "body": item.get("contenu", "")
        },
        "metadata": {
            "created_at": item.get("date_creation", ""),
            "type": item.get("type", "")
        }
    }
    return result

# Cr√©er le processeur avec votre mapper
processor = GenericJsonProcessor(custom_mapper=mon_mapper_personnalise)
processor.process_file("mon_fichier.json", "resultat.json")
```

## üîÑ Int√©gration avec Temporal

Pour int√©grer cette solution dans vos workflows Temporal :

```javascript
// Exemple simplifi√© d'activit√© Temporal en JavaScript
export async function syncJiraAndIndex(ctx) {
  // 1. Ex√©cuter le traitement JIRA
  const processOutput = await executeCommand(
    'python', 
    ['run_analysis.py', '--files', 'export_jira.json', '--output-dir', 'jira_processed']
  );
  
  // 2. Lire les r√©sultats transform√©s
  const processedData = await fs.readFile('jira_processed/llm_ready_jira.json', 'utf8');
  
  // 3. Mettre √† jour l'index Llamendex avec les donn√©es transform√©es
  await llamendexClient.updateIndex('JiraIndex', JSON.parse(processedData));
  
  return { status: 'completed', ticketsProcessed: processedData.items.length };
}
```

## üìù Format pour Llamendex

La structure de sortie est optimis√©e pour Llamendex, permettant une conversion directe en `NodeWithScore` :

```json
{
  "items": [
    {
      "id": "IDENTIFIANT",
      "title": "TITRE",
      "content": {
        "field1": "CONTENU1",
        "field2": "CONTENU2"
      },
      "metadata": {
        "created_at": "DATE",
        "author": "AUTEUR"
      },
      "analysis": {
        "keywords": ["MOT1", "MOT2"],
        "entities": {
          "ids": ["ID1", "ID2"],
          "urls": ["URL1", "URL2"]
        }
      },
      "relationships": {
        "confluence_links": [],
        "jira_tickets": []
      }
    }
  ],
  "metadata": {
    "source_file": "fichier_source.json",
    "processed_at": "DATE_TRAITEMENT",
    "structure": { ... }
  }
}
```

## ‚ö†Ô∏è D√©pendances

- Python 3.8+
- dotenv, ijson, openai
- Modules standards (json, os, datetime, etc.) 