# JSON Processor & CLI - Solution compl√®te pour le traitement et l'analyse de donn√©es

## üöÄ Vue d'ensemble

Ce projet fournit une solution compl√®te pour traiter, analyser et transformer des fichiers JSON provenant de diff√©rentes sources (JIRA, Confluence, GitHub, etc.), en pr√©paration pour l'indexation dans un syst√®me RAG avec Llamendex.

Il se compose de deux modules principaux :
- **CLI** : Interface en ligne de commande interactive et puissante pour toutes les op√©rations
- **Extract** : Moteur de traitement flexible pour l'analyse et la transformation des donn√©es

## üéØ Objectifs et fonctionnalit√©s principales

- **D√©tection automatique** de type de fichier (JIRA, Confluence, GitHub)
- **Transformation flexible** via des mappings personnalisables
- **Mode interactif complet** avec assistant guid√© pour toutes les op√©rations
- **D√©coupage et traitement** de fichiers volumineux
- **Extraction de m√©tadonn√©es** structur√©es
- **√âtablissement de correspondances** entre diff√©rentes sources
- **Extraction structur√©e avec Outlines** pour une g√©n√©ration contrainte par sch√©ma
- **Enrichissement par LLM** (OpenAI) pour l'analyse s√©mantique
- **Arborescences d√©taill√©es** du contenu de chaque fichier trait√©
- **Organisation automatique** des r√©sultats avec timestamps uniques

## ‚öôÔ∏è Installation

1. Clonez ce d√©p√¥t et acc√©dez au dossier
2. Cr√©ez un fichier `.env` en copiant `.env.example`
3. Installez les d√©pendances :

```bash
pip install -r requirements.txt
```

### Configuration d'Outlines (optionnelle)

Le syst√®me utilise la biblioth√®que [Outlines](https://github.com/dottxt/outlines) (v0.2.3) pour l'extraction structur√©e de donn√©es. Deux modes de fonctionnement sont disponibles :

1. **Mode complet** : Avec la biblioth√®que Outlines install√©e et une cl√© API OpenAI
2. **Mode stub** : Fonctionnement d√©grad√© sans Outlines ou sans cl√© API

Le syst√®me d√©tecte automatiquement la configuration disponible et s'adapte en cons√©quence. Pour v√©rifier votre installation :

```bash
python test_outlines_integration.py
```

## üìñ Guide d'utilisation rapide

### Mode interactif (recommand√©)

Lancez l'assistant complet qui vous guide √©tape par √©tape :

```bash
python -m cli.cli interactive
```

### Traitement de fichiers JSON

```bash
python -m cli.cli process mon_fichier.json --output resultat.json
```

### Avec extraction structur√©e Outlines

```bash
python -m cli.cli process mon_fichier.json --outlines --llm
```

### D√©coupage de fichiers volumineux

```bash
python -m cli.cli chunks mon_gros_fichier.json --output-dir dossier_morceaux --items-per-file 500
```

### Correspondances entre JIRA et Confluence

```bash
python -m cli.cli match jira_processed.json confluence_processed.json --output-dir resultats_match
```

### Flux de traitement complet

```bash
python -m cli.cli unified jira1.json jira2.json --confluence conf1.json conf2.json --output-dir resultats_complets
```

## üìä Organisation des r√©sultats

Tous les r√©sultats sont organis√©s dans le dossier `results/` avec une structure claire :

```
results/
‚îú‚îÄ‚îÄ jira_confluence_2023-08-30-14-22-55/     # Dossier d'une ex√©cution unified
‚îÇ   ‚îú‚îÄ‚îÄ jira/                               # Sous-dossier pour les fichiers JIRA
‚îÇ   ‚îú‚îÄ‚îÄ confluence/                         # Sous-dossier pour les fichiers Confluence
‚îÇ   ‚îú‚îÄ‚îÄ matches/                            # Sous-dossier pour les correspondances
‚îÇ   ‚îú‚îÄ‚îÄ split_jira_files/                   # Fichiers JIRA d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ split_confluence_files/             # Fichiers Confluence d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ llm_ready/                          # Fichiers pr√™ts pour LLM
‚îÇ   ‚îú‚îÄ‚îÄ global_arborescence.txt             # Arborescence globale
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

## üîç Approche flexible et g√©n√©rique

L'approche adopt√©e permet de traiter n'importe quelle structure JSON, gr√¢ce √† :

1. **D√©tection automatique de structure** : Analyse des champs importants
2. **Mappers personnalisables** : Adaptation √† n'importe quel format
3. **Traitement par morceaux** : Gestion efficace de fichiers volumineux
4. **Transformation flexible** : Structure de sortie adaptable

## üí° Syst√®me de fallback robuste

Notre solution est con√ßue pour fonctionner dans diff√©rents environnements, gr√¢ce √† un syst√®me de fallback √† plusieurs niveaux :

1. **Outlines + OpenAI** : Utilisation compl√®te des fonctionnalit√©s d'extraction structur√©e
2. **Sans OpenAI** : Outlines fonctionne en mode d√©grad√©, certaines fonctionnalit√©s d√©sactiv√©es
3. **Sans Outlines** : Le syst√®me utilise des stubs internes qui imitent l'API d'Outlines
4. **Fallback standard** : En dernier recours, utilisation du parseur JSON standard

Cette architecture garantit que le syst√®me reste op√©rationnel m√™me sans connexion internet ou cl√© API.

## üß© Extension du syst√®me

### Cr√©er vos propres mappers

Pour adapter la solution √† de nouvelles sources :

```python
from generic_json_processor import GenericJsonProcessor

def mon_mapper_personnalise(item):
    # Transformer l'item selon vos besoins
    result = {
        "id": item.get("identifiant", ""),
        "content": {
            "title": item.get("nom", ""),
            "body": item.get("contenu", "")
        },
        "metadata": {
            "created_at": item.get("date_creation", ""),
            "type": item.get("type", "")
        }
    }
    return result

# Cr√©er le processeur avec votre mapper
processor = GenericJsonProcessor(custom_mapper=mon_mapper_personnalise)
processor.process_file("mon_fichier.json", "resultat.json")
```

### Utiliser Outlines pour l'extraction structur√©e

```python
from extract import outlines_robust_json_parser, extract_structured_data

# Parser un fichier JSON avec Outlines
data = outlines_robust_json_parser("mon_fichier.json", llm_fallback=True)

# Extraire des donn√©es structur√©es selon un sch√©ma
schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "categories": {
            "type": "array",
            "items": {"type": "string"}
        }
    }
}
result = extract_structured_data(text_content, schema)
```

## üîÑ Int√©gration avec Temporal

Notre solution s'int√®gre parfaitement avec des workflows Temporal :

| **Workflow Temporal** | **Index associ√©** | **Notre solution** |
|------------------------|-------------------|---------------------|
| `SyncJiraAndIndex` | `JiraIndex` | Utilise notre processeur avec mapping JIRA |
| `SyncConfluenceAndIndex` | `ConfluenceIndex` | Utilise notre processeur avec mapping Confluence |
| `HandleUserQueryToAgent` | (tous) | Interroge les donn√©es transform√©es par notre solution |

## üìù Format pour Llamendex

La structure de sortie est optimis√©e pour Llamendex, permettant une conversion directe en `NodeWithScore` :

```json
{
  "items": [
    {
      "id": "IDENTIFIANT",
      "title": "TITRE",
      "content": {
        "field1": "CONTENU1",
        "field2": "CONTENU2"
      },
      "metadata": {
        "created_at": "DATE",
        "author": "AUTEUR"
      },
      "analysis": {
        "keywords": ["MOT1", "MOT2"],
        "entities": {
          "ids": ["ID1", "ID2"],
          "urls": ["URL1", "URL2"]
        }
      },
      "relationships": {
        "confluence_links": [],
        "jira_tickets": []
      }
    }
  ],
  "metadata": {
    "source_file": "fichier_source.json",
    "processed_at": "DATE_TRAITEMENT",
    "structure": { ... }
  }
}
```

## ‚ö†Ô∏è D√©pendances

- Python 3.8+
- typer, rich, inquirer, python-dotenv, ijson
- openai (optionnel, pour les fonctionnalit√©s LLM)
- outlines==0.2.3 (optionnel, pour l'extraction structur√©e)

## üìú Licence

Ce projet est distribu√© sous licence MIT. 