# JSON Processor & CLI pour Llamendex - Extraction et analyse robuste de donn√©es structur√©es

## üîç Introduction

Ce projet est une solution compl√®te pour traiter, analyser et transformer des fichiers JSON provenant de diff√©rentes sources (JIRA, Confluence, GitHub, etc.) en pr√©paration pour l'indexation dans Llamendex ou tout autre syst√®me RAG moderne.

La particularit√© de cette solution r√©side dans sa capacit√© √† **s'adapter automatiquement √† n'importe quelle structure JSON** et √† garantir un traitement robuste des fichiers, m√™me en pr√©sence d'erreurs ou d'incoh√©rences. Contrairement aux outils g√©n√©riques de traitement JSON, notre solution allie:

- **D√©tection intelligente** de la structure des donn√©es
- **Pr√©servation des fichiers sources** (jamais modifi√©s directement)
- **Enrichissement s√©mantique par LLM** avec Outlines
- **Rapports d√©taill√©s** g√©n√©r√©s automatiquement
- **Correction automatique** des erreurs de syntaxe JSON
- **Interface CLI interactive** et accessible

### Pourquoi cette solution ?

Dans le d√©veloppement de syst√®mes RAG (Retrieval Augmented Generation) comme Llamendex, l'ingestion de donn√©es de qualit√© est cruciale. Pourtant, nous faisons face √† plusieurs d√©fis concrets :

1. **H√©t√©rog√©n√©it√© des sources** : Chaque syst√®me (JIRA, Confluence, GitHub) exporte des structures JSON diff√©rentes
2. **Fichiers mal form√©s** : Les exports contiennent souvent des erreurs syntaxiques ou structurelles
3. **Volumes importants** : Les exports peuvent atteindre plusieurs gigaoctets, d√©passant les capacit√©s de traitement standard
4. **Perte de contexte** : L'enrichissement manuel des donn√©es est chronophage et inconsistant
5. **Absence de correspondances** : Les liens entre tickets JIRA et pages Confluence sont souvent perdus

Notre solution r√©pond √† ces d√©fis en proposant un pipeline complet et robuste qui :
- D√©tecte et r√©pare automatiquement les probl√®mes de structure
- Standardise les donn√©es dans un format optimal pour les syst√®mes RAG
- Enrichit le contenu gr√¢ce √† des LLM pour am√©liorer la recherche s√©mantique
- √âtablit des correspondances entre diff√©rentes sources de donn√©es
- G√©n√®re automatiquement des r√©sum√©s et analyses pour faciliter l'ingestion

De plus, contrairement aux outils ETL g√©n√©riques ou aux solutions de traitement tabulaire comme pandas, notre solution est sp√©cifiquement con√ßue pour pr√©parer des donn√©es textuelles riches pour les syst√®mes de RAG, avec une attention particuli√®re √† la pr√©servation du contexte et √† l'enrichissement s√©mantique.

## ÔøΩÔøΩ Vue d'ensemble

Le projet se compose de trois modules principaux :
- **CLI** : Interface en ligne de commande interactive et puissante pour toutes les op√©rations
- **Extract** : Moteur de traitement flexible pour l'analyse et la transformation des donn√©es
- **Tools** : Utilitaires pour r√©soudre des probl√®mes sp√©cifiques (nettoyage, validation)

## üéØ Fonctionnalit√©s principales

- **D√©tection automatique** de type de fichier (JIRA, Confluence, GitHub)
- **Transformation flexible** via des mappings personnalisables
- **Mode interactif complet** avec assistant guid√© pour toutes les op√©rations
- **D√©coupage et traitement** de fichiers volumineux
- **Extraction de m√©tadonn√©es** structur√©es
- **√âtablissement de correspondances** entre diff√©rentes sources
- **Extraction structur√©e avec Outlines** pour une g√©n√©ration contrainte par sch√©ma
- **Enrichissement par LLM** (OpenAI) pour l'analyse s√©mantique
- **Arborescences d√©taill√©es** du contenu de chaque fichier trait√©
- **Organisation automatique** des r√©sultats avec timestamps uniques
- **R√©sum√©s LLM g√©n√©r√©s automatiquement** pour chaque traitement
- **Gestion robuste des erreurs** avec diff√©rents niveaux de fallback

## ‚öôÔ∏è Installation

1. Clonez ce d√©p√¥t et acc√©dez au dossier
2. Cr√©ez un fichier `.env` en copiant `.env.example`
3. Installez les d√©pendances :

```bash
pip install -r requirements.txt
```

### Configuration d'Outlines (optionnelle)

Le syst√®me utilise la biblioth√®que [Outlines](https://github.com/dottxt/outlines) (v0.2.3) pour l'extraction structur√©e de donn√©es. Deux modes de fonctionnement sont disponibles :

1. **Mode complet** : Avec la biblioth√®que Outlines install√©e et une cl√© API OpenAI
2. **Mode stub** : Fonctionnement d√©grad√© sans Outlines ou sans cl√© API

Le syst√®me d√©tecte automatiquement la configuration disponible et s'adapte en cons√©quence. Pour v√©rifier votre installation :

```bash
python -m tests.test_outlines_integration
```

## üìñ Guide d'utilisation rapide

### Mode interactif (recommand√©)

Lancez l'assistant complet qui vous guide √©tape par √©tape :

```bash
python -m cli.cli interactive
```

### Traitement de fichiers JSON

```bash
python -m cli.cli process mon_fichier.json --output resultat.json
```

### Avec enrichissement LLM et pr√©servation des sources

```bash
python -m cli.cli process mon_fichier.json --llm --preserve-source
```

### D√©coupage de fichiers volumineux

```bash
python -m cli.cli chunks mon_gros_fichier.json --output-dir dossier_morceaux --items-per-file 500
```

### Correspondances entre JIRA et Confluence

```bash
python -m cli.cli match jira_processed.json confluence_processed.json --output-dir resultats_match
```

### Flux de traitement complet

```bash
python -m cli.cli unified jira1.json jira2.json --confluence conf1.json conf2.json --output-dir resultats_complets
```

## üìä Organisation des r√©sultats

Tous les r√©sultats sont organis√©s dans le dossier `results/` avec une structure claire :

```
results/
‚îú‚îÄ‚îÄ jira_confluence_2023-08-30-14-22-55/     # Dossier d'une ex√©cution unified
‚îÇ   ‚îú‚îÄ‚îÄ jira/                               # Sous-dossier pour les fichiers JIRA
‚îÇ   ‚îú‚îÄ‚îÄ confluence/                         # Sous-dossier pour les fichiers Confluence
‚îÇ   ‚îú‚îÄ‚îÄ matches/                            # Sous-dossier pour les correspondances
‚îÇ   ‚îú‚îÄ‚îÄ split_jira_files/                   # Fichiers JIRA d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ split_confluence_files/             # Fichiers Confluence d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ llm_ready/                          # Fichiers pr√™ts pour LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_jira.json              # JIRA enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_confluence.json        # Confluence enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jira_llm_enrichment_summary.md  # R√©sum√© LLM pour JIRA
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ confluence_llm_enrichment_summary.md # R√©sum√© LLM pour Confluence
‚îÇ   ‚îú‚îÄ‚îÄ global_arborescence.txt             # Arborescence globale
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

## üß† R√©sum√©s LLM automatiques

Pour chaque traitement utilisant un LLM, un rapport de r√©sum√© est automatiquement g√©n√©r√© au format Markdown:

```markdown
# R√©sum√© de l'enrichissement LLM

## Informations g√©n√©rales
- Date d'analyse: 2025-05-08 23:34:37
- Nombre total d'√©l√©ments analys√©s: 42
- Mod√®le LLM utilis√©: gpt-4

## Analyse
### Mots-cl√©s principaux extraits
projet, d√©veloppement, API, backend, utilisateur, interface, base de donn√©es

### Distribution des sentiments
{'positive': 12, 'neutral': 25, 'negative': 5}

### Exemple d'enrichissement
**Ticket**: PROJ-123 - Impl√©mentation de l'authentification OAuth2
**R√©sum√© LLM**: Ce ticket concerne l'int√©gration du protocole OAuth2 pour s√©curiser l'API...
```

Ces r√©sum√©s permettent:
1. Une vue d'ensemble rapide du contenu trait√©
2. L'extraction des principaux th√®mes et sentiments
3. Des exemples concrets d'enrichissement LLM
4. Une pr√©paration optimale pour l'ingestion dans Llamendex

## üîç Approche flexible et g√©n√©rique

L'approche adopt√©e permet de traiter n'importe quelle structure JSON, gr√¢ce √† :

1. **D√©tection automatique de structure** : Analyse des champs importants
2. **Mappers personnalisables** : Adaptation √† n'importe quel format
3. **Traitement par morceaux** : Gestion efficace de fichiers volumineux
4. **Transformation flexible** : Structure de sortie adaptable
5. **Pr√©servation des sources** : Travail uniquement sur des copies

## üí° Syst√®me de fallback robuste

Notre solution est con√ßue pour fonctionner dans diff√©rents environnements, gr√¢ce √† un syst√®me de fallback √† plusieurs niveaux :

1. **Outlines + OpenAI** : Utilisation compl√®te des fonctionnalit√©s d'extraction structur√©e
2. **Sans OpenAI** : Outlines fonctionne en mode d√©grad√©, certaines fonctionnalit√©s d√©sactiv√©es
3. **Sans Outlines** : Le syst√®me utilise des stubs internes qui imitent l'API d'Outlines
4. **Fallback standard** : En dernier recours, utilisation du parseur JSON standard

Cette architecture garantit que le syst√®me reste op√©rationnel m√™me sans connexion internet ou cl√© API.

## üõ†Ô∏è Utilitaires

Le projet inclut des outils pratiques dans le dossier `tools/` :

1. **check_json.py** : V√©rifier la validit√© des fichiers JSON
   ```bash
   python -m tools.check_json chemin/vers/fichier.json
   ```

2. **fix_paths.py** : Corriger les probl√®mes de chemins et r√©parer les fichiers JSON
   ```bash
   python -m tools.fix_paths --all --source-dir=files --target-dir=results/fixed
   ```

## üß© Extension du syst√®me

### Cr√©er vos propres mappers

Pour adapter la solution √† de nouvelles sources :

```python
from extract.generic_json_processor import GenericJsonProcessor

def mon_mapper_personnalise(item):
    # Transformer l'item selon vos besoins
    result = {
        "id": item.get("identifiant", ""),
        "content": {
            "title": item.get("nom", ""),
            "body": item.get("contenu", "")
        },
        "metadata": {
            "created_at": item.get("date_creation", ""),
            "type": item.get("type", "")
        }
    }
    return result

# Cr√©er le processeur avec votre mapper
processor = GenericJsonProcessor(custom_mapper=mon_mapper_personnalise)
processor.process_file("mon_fichier.json", "resultat.json")
```

### Utiliser Outlines pour l'extraction structur√©e

```python
from extract.outlines_enhanced_parser import outlines_robust_json_parser
from extract.outlines_extractor import extract_structured_data

# Parser un fichier JSON avec Outlines
data = outlines_robust_json_parser("mon_fichier.json", llm_fallback=True)

# Extraire des donn√©es structur√©es selon un sch√©ma
schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "categories": {
            "type": "array",
            "items": {"type": "string"}
        }
    }
}
result = extract_structured_data(text_content, schema)
```

## üîÑ Int√©gration avec Temporal et Llamendex

Notre solution s'int√®gre parfaitement avec des workflows Temporal et Llamendex :

| **Workflow Temporal** | **Index associ√©** | **Notre solution** |
|------------------------|-------------------|---------------------|
| `SyncJiraAndIndex` | `JiraIndex` | Utilise notre processeur avec mapping JIRA |
| `SyncConfluenceAndIndex` | `ConfluenceIndex` | Utilise notre processeur avec mapping Confluence |
| `HandleUserQueryToAgent` | (tous) | Interroge les donn√©es transform√©es par notre solution |

## üìù Format pour Llamendex

La structure de sortie est optimis√©e pour Llamendex, permettant une conversion directe en `NodeWithScore` :

```json
{
  "items": [
    {
      "id": "IDENTIFIANT",
      "title": "TITRE",
      "content": {
        "field1": "CONTENU1",
        "field2": "CONTENU2"
      },
      "metadata": {
        "created_at": "DATE",
        "author": "AUTEUR"
      },
      "analysis": {
        "llm_summary": "R√©sum√© concis g√©n√©r√© par LLM",
        "llm_keywords": ["MOT1", "MOT2"],
        "llm_entities": {
          "people": ["PERSONNE1", "PERSONNE2"],
          "organizations": ["ORG1", "ORG2"]
        },
        "llm_sentiment": "positive"
      },
      "relationships": {
        "confluence_links": [],
        "jira_tickets": []
      }
    }
  ],
  "metadata": {
    "source_file": "fichier_source.json",
    "processed_at": "DATE_TRAITEMENT",
    "llm_enrichment": {
      "model": "gpt-4",
      "enrichment_date": "DATE_ENRICHISSEMENT"
    }
  }
}
```

## ‚ö†Ô∏è D√©pendances

- Python 3.8+
- typer, rich, inquirer, python-dotenv, ijson
- openai (optionnel, pour les fonctionnalit√©s LLM)
- outlines==0.2.3 (optionnel, pour l'extraction structur√©e)

## üìú Licence

Ce projet est distribu√© sous licence MIT. 