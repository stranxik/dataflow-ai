# JSON Processor & CLI pour Llamendex - Extraction et analyse robuste de donn√©es structur√©es

![Version](https://img.shields.io/badge/version-1.0-blue) ![Python](https://img.shields.io/badge/Python-3.8%2B-green) ![License](https://img.shields.io/badge/license-MIT-orange)

## üîç Introduction

Ce projet est une solution compl√®te pour traiter, analyser et transformer des fichiers JSON provenant de diff√©rentes sources (JIRA, Confluence, GitHub, etc.) en pr√©paration pour l'indexation dans Llamendex ou tout autre syst√®me RAG moderne.

La particularit√© de cette solution r√©side dans sa capacit√© √† **s'adapter automatiquement √† n'importe quelle structure JSON** et √† garantir un traitement robuste des fichiers, m√™me en pr√©sence d'erreurs ou d'incoh√©rences. Contrairement aux outils g√©n√©riques de traitement JSON, notre solution allie:

- **D√©tection intelligente** de la structure des donn√©es
- **Pr√©servation des fichiers sources** (jamais modifi√©s directement)
- **Enrichissement s√©mantique par LLM** avec Outlines
- **Rapports d√©taill√©s** g√©n√©r√©s automatiquement
- **Correction automatique** des erreurs de syntaxe JSON
- **Interface CLI interactive** et accessible

> üí° **NOUVEAU!** Int√©gration compl√®te des outils de s√©curit√© et de nettoyage des donn√©es sensibles directement dans l'interface CLI et dans les processeurs JSON.

### Pourquoi cette solution ?

Dans le d√©veloppement de syst√®mes RAG (Retrieval Augmented Generation) comme Llamendex, l'ingestion de donn√©es de qualit√© est cruciale. Pourtant, nous faisons face √† plusieurs d√©fis concrets :

1. **H√©t√©rog√©n√©it√© des sources** : Chaque syst√®me (JIRA, Confluence, GitHub) exporte des structures JSON diff√©rentes
2. **Fichiers mal form√©s** : Les exports contiennent souvent des erreurs syntaxiques ou structurelles
3. **Volumes importants** : Les exports peuvent atteindre plusieurs gigaoctets, d√©passant les capacit√©s de traitement standard
4. **Perte de contexte** : L'enrichissement manuel des donn√©es est chronophage et inconsistant
5. **Absence de correspondances** : Les liens entre tickets JIRA et pages Confluence sont souvent perdus

Notre solution r√©pond √† ces d√©fis en proposant un pipeline complet et robuste qui :
- D√©tecte et r√©pare automatiquement les probl√®mes de structure
- Standardise les donn√©es dans un format optimal pour les syst√®mes RAG
- Enrichit le contenu gr√¢ce √† des LLM pour am√©liorer la recherche s√©mantique
- √âtablit des correspondances entre diff√©rentes sources de donn√©es
- G√©n√®re automatiquement des r√©sum√©s et analyses pour faciliter l'ingestion

De plus, contrairement aux outils ETL g√©n√©riques ou aux solutions de traitement tabulaire comme pandas, notre solution est sp√©cifiquement con√ßue pour pr√©parer des donn√©es textuelles riches pour les syst√®mes de RAG, avec une attention particuli√®re √† la pr√©servation du contexte et √† l'enrichissement s√©mantique.

## üéØ Vue d'ensemble

Le projet se compose de trois modules principaux :
- **CLI** : Interface en ligne de commande interactive et puissante pour toutes les op√©rations
- **Extract** : Moteur de traitement flexible pour l'analyse et la transformation des donn√©es
- **Tools** : Utilitaires pour r√©soudre des probl√®mes sp√©cifiques (nettoyage, validation)

<!-- D√âBUT ENCART DE R√âF√âRENCE RAPIDE -->
<div align="center">

## üìã Guide de r√©f√©rence rapide

</div>

| Commande | Description | Exemple |
|---------|-------------|---------|
| `interactive` | **Mode interactif** avec assistant guid√© | `python -m cli.cli interactive` |
| `process` | **Traiter** un fichier JSON | `python -m cli.cli process fichier.json --llm` |
| `chunks` | **D√©couper** un fichier volumineux | `python -m cli.cli chunks gros_fichier.json --items-per-file 500` |
| `match` | **Correspondances** JIRA-Confluence | `python -m cli.cli match jira.json confluence.json` |
| `unified` | **Flux complet** de traitement | `python -m cli.cli unified jira1.json jira2.json --confluence conf1.json` |
| `clean` | **Nettoyer** les donn√©es sensibles | `python -m cli.cli clean fichier.json --recursive` |

<div align="center">

### üõ†Ô∏è Outils ind√©pendants

</div>

| Outil | Description | Exemple |
|-------|-------------|---------|
| `check_json.py` | **V√©rifier** la validit√© des fichiers JSON | `python -m tools.check_json fichier.json` |
| `clean_sensitive_data.py` | **Nettoyer** les donn√©es sensibles | `python -m tools.clean_sensitive_data fichier.json` |
| `fix_paths.py` | **R√©parer** les chemins et les fichiers | `python -m tools.fix_paths --all --source-dir=files` |

<!-- FIN ENCART DE R√âF√âRENCE RAPIDE -->

## üéØ Fonctionnalit√©s principales

- **D√©tection automatique** de type de fichier (JIRA, Confluence, GitHub)
- **Transformation flexible** via des mappings personnalisables
- **Mode interactif complet** avec assistant guid√© pour toutes les op√©rations
- **D√©coupage et traitement** de fichiers volumineux
- **Extraction de m√©tadonn√©es** structur√©es
- **√âtablissement de correspondances** entre diff√©rentes sources
- **Extraction structur√©e avec Outlines** pour une g√©n√©ration contrainte par sch√©ma
- **Enrichissement par LLM** (OpenAI) pour l'analyse s√©mantique
- **Arborescences d√©taill√©es** du contenu de chaque fichier trait√©
- **Organisation automatique** des r√©sultats avec timestamps uniques
- **R√©sum√©s LLM g√©n√©r√©s automatiquement** pour chaque traitement
- **Gestion robuste des erreurs** avec diff√©rents niveaux de fallback

## ‚öôÔ∏è Installation

1. Clonez ce d√©p√¥t et acc√©dez au dossier
2. Cr√©ez un fichier `.env` en copiant `.env.example`
3. Installez les d√©pendances :

```bash
pip install -r requirements.txt
```

### Configuration d'Outlines (optionnelle)

Le syst√®me utilise la biblioth√®que [Outlines](https://github.com/dottxt/outlines) (v0.2.3) pour l'extraction structur√©e de donn√©es. Deux modes de fonctionnement sont disponibles :

1. **Mode complet** : Avec la biblioth√®que Outlines install√©e et une cl√© API OpenAI
2. **Mode stub** : Fonctionnement d√©grad√© sans Outlines ou sans cl√© API

Le syst√®me d√©tecte automatiquement la configuration disponible et s'adapte en cons√©quence. Pour v√©rifier votre installation :

```bash
python -m tests.test_outlines_integration
```

## üìñ Guide d'utilisation rapide

<div class="command-box">

### üîç Mode interactif (recommand√©)

Lancez l'assistant complet qui vous guide √©tape par √©tape :

```bash
python -m cli.cli interactive
```

</div>

<div class="command-box">

### üìÑ Traitement de fichiers JSON

```bash
python -m cli.cli process mon_fichier.json --output resultat.json
```

#### Avec enrichissement LLM et pr√©servation des sources

```bash
python -m cli.cli process mon_fichier.json --llm --preserve-source
```

</div>

<div class="command-box">

### üî™ D√©coupage de fichiers volumineux

```bash
python -m cli.cli chunks mon_gros_fichier.json --output-dir dossier_morceaux --items-per-file 500
```

</div>

<div class="command-box">

### üîó Correspondances entre JIRA et Confluence

```bash
python -m cli.cli match jira_processed.json confluence_processed.json --output-dir resultats_match
```

</div>

<div class="command-box">

### üöÄ Flux de traitement complet

```bash
python -m cli.cli unified jira1.json jira2.json --confluence conf1.json conf2.json --output-dir resultats_complets
```

</div>

<div class="command-box">

### üßπ Nettoyage des donn√©es sensibles

```bash
python -m cli.cli clean fichier.json --output fichier_propre.json
```

</div>

## üìä Organisation des r√©sultats

Tous les r√©sultats sont organis√©s dans le dossier `results/` avec une structure claire :

```
results/
‚îú‚îÄ‚îÄ jira_confluence_2023-08-30-14-22-55/     # Dossier d'une ex√©cution unified
‚îÇ   ‚îú‚îÄ‚îÄ jira/                               # Sous-dossier pour les fichiers JIRA
‚îÇ   ‚îú‚îÄ‚îÄ confluence/                         # Sous-dossier pour les fichiers Confluence
‚îÇ   ‚îú‚îÄ‚îÄ matches/                            # Sous-dossier pour les correspondances
‚îÇ   ‚îú‚îÄ‚îÄ split_jira_files/                   # Fichiers JIRA d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ split_confluence_files/             # Fichiers Confluence d√©coup√©s
‚îÇ   ‚îú‚îÄ‚îÄ llm_ready/                          # Fichiers pr√™ts pour LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_jira.json              # JIRA enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enriched_confluence.json        # Confluence enrichi avec LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jira_llm_enrichment_summary.md  # R√©sum√© LLM pour JIRA
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ confluence_llm_enrichment_summary.md # R√©sum√© LLM pour Confluence
‚îÇ   ‚îú‚îÄ‚îÄ global_arborescence.txt             # Arborescence globale
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

## üß† R√©sum√©s LLM automatiques

> üìù **Fonctionnalit√© avanc√©e**: Pour chaque traitement utilisant un LLM, un rapport de r√©sum√© est automatiquement g√©n√©r√© au format Markdown.

Exemple de r√©sum√© g√©n√©r√©:

<details>
<summary>üëâ Voir un exemple de r√©sum√© LLM (cliquez pour d√©velopper)</summary>

```markdown
# R√©sum√© de l'enrichissement LLM

## Informations g√©n√©rales
- Date d'analyse: 2025-05-08 23:34:37
- Nombre total d'√©l√©ments analys√©s: 42
- Mod√®le LLM utilis√©: gpt-4

## Analyse
### Mots-cl√©s principaux extraits
projet, d√©veloppement, API, backend, utilisateur, interface, base de donn√©es

### Distribution des sentiments
{'positive': 12, 'neutral': 25, 'negative': 5}

### Exemple d'enrichissement
**Ticket**: PROJ-123 - Impl√©mentation de l'authentification OAuth2
**R√©sum√© LLM**: Ce ticket concerne l'int√©gration du protocole OAuth2 pour s√©curiser l'API...
```

</details>

Ces r√©sum√©s permettent:
1. Une vue d'ensemble rapide du contenu trait√©
2. L'extraction des principaux th√®mes et sentiments
3. Des exemples concrets d'enrichissement LLM
4. Une pr√©paration optimale pour l'ingestion dans Llamendex

## üîç Approche flexible et g√©n√©rique

L'approche adopt√©e permet de traiter n'importe quelle structure JSON, gr√¢ce √† :

1. **D√©tection automatique de structure** : Analyse des champs importants
2. **Mappers personnalisables** : Adaptation √† n'importe quel format
3. **Traitement par morceaux** : Gestion efficace de fichiers volumineux
4. **Transformation flexible** : Structure de sortie adaptable
5. **Pr√©servation des sources** : Travail uniquement sur des copies

## üí° Syst√®me de fallback robuste

Notre solution est con√ßue pour fonctionner dans diff√©rents environnements, gr√¢ce √† un syst√®me de fallback √† plusieurs niveaux :

| Niveau | Configuration | Fonctionnalit√©s |
|--------|--------------|-----------------|
| **1** | Outlines + OpenAI | Extraction structur√©e compl√®te, r√©paration automatique |
| **2** | Sans OpenAI | Mode d√©grad√© d'Outlines, certaines fonctionnalit√©s d√©sactiv√©es |
| **3** | Sans Outlines | Utilisation de stubs internes imitant l'API d'Outlines |
| **4** | Fallback standard | Parseur JSON standard en dernier recours |

Cette architecture garantit que le syst√®me reste op√©rationnel m√™me sans connexion internet ou cl√© API.

## üõ†Ô∏è Utilitaires

Le projet inclut des outils pratiques dans le dossier `tools/` :

1. **check_json.py** : V√©rifier la validit√© des fichiers JSON
   ```bash
   python -m tools.check_json chemin/vers/fichier.json
   ```

2. **fix_paths.py** : Corriger les probl√®mes de chemins et r√©parer les fichiers JSON
   ```bash
   python -m tools.fix_paths --all --source-dir=files --target-dir=results/fixed
   ```

3. **clean_sensitive_data.py** : Nettoyer les donn√©es sensibles (cl√©s API, emails, etc.)
   ```bash
   python -m tools.clean_sensitive_data fichier.json --output fichier_clean.json
   ```

### Utilisation des outils dans le CLI

Les outils sont int√©gr√©s au CLI principal et peuvent √™tre utilis√©s de mani√®re interactive :

```bash
# Lancer le nettoyage des donn√©es sensibles via le CLI
python -m cli.cli clean fichier.json --output fichier_clean.json

# Utiliser le mode interactif
python -m cli.cli interactive
# Puis s√©lectionner "Nettoyer les donn√©es sensibles (clean)"
```

### Int√©gration programmatique

Les outils peuvent √©galement √™tre import√©s et utilis√©s directement dans votre code :

```python
# V√©rifier la validit√© d'un fichier JSON
from tools import validate_file
is_valid, error_msg = validate_file("mon_fichier.json")
if not is_valid:
    print(f"Erreur dans le fichier: {error_msg}")

# Nettoyer les donn√©es sensibles
from tools import clean_json_file
clean_json_file("fichier_avec_api_keys.json", "fichier_securise.json")

# Corriger les chemins dupliqu√©s
from tools import fix_duplicate_paths
fix_duplicate_paths("dossier_r√©sultats")
```

Le traitement principal via `GenericJsonProcessor` int√®gre automatiquement ces outils pour v√©rifier la validit√© des fichiers JSON et nettoyer les donn√©es sensibles avant sauvegarde.

## üß© Extension du syst√®me

### Cr√©er vos propres mappers

Pour adapter la solution √† de nouvelles sources :

```python
from extract.generic_json_processor import GenericJsonProcessor

def mon_mapper_personnalise(item):
    # Transformer l'item selon vos besoins
    result = {
        "id": item.get("identifiant", ""),
        "content": {
            "title": item.get("nom", ""),
            "body": item.get("contenu", "")
        },
        "metadata": {
            "created_at": item.get("date_creation", ""),
            "type": item.get("type", "")
        }
    }
    return result

# Cr√©er le processeur avec votre mapper
processor = GenericJsonProcessor(custom_mapper=mon_mapper_personnalise)
processor.process_file("mon_fichier.json", "resultat.json")
```

### Utiliser Outlines pour l'extraction structur√©e

```python
from extract.outlines_enhanced_parser import outlines_robust_json_parser
from extract.outlines_extractor import extract_structured_data

# Parser un fichier JSON avec Outlines
data = outlines_robust_json_parser("mon_fichier.json", llm_fallback=True)

# Extraire des donn√©es structur√©es selon un sch√©ma
schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "categories": {
            "type": "array",
            "items": {"type": "string"}
        }
    }
}
result = extract_structured_data(text_content, schema)
```

## üîÑ Int√©gration avec Temporal et Llamendex

Notre solution s'int√®gre parfaitement avec des workflows Temporal et Llamendex :

| **Workflow Temporal** | **Index associ√©** | **Notre solution** |
|------------------------|-------------------|---------------------|
| `SyncJiraAndIndex` | `JiraIndex` | Utilise notre processeur avec mapping JIRA |
| `SyncConfluenceAndIndex` | `ConfluenceIndex` | Utilise notre processeur avec mapping Confluence |
| `HandleUserQueryToAgent` | (tous) | Interroge les donn√©es transform√©es par notre solution |

## üìù Format pour Llamendex

La structure de sortie est optimis√©e pour Llamendex, permettant une conversion directe en `NodeWithScore` :

```json
{
  "items": [
    {
      "id": "IDENTIFIANT",
      "title": "TITRE",
      "content": {
        "field1": "CONTENU1",
        "field2": "CONTENU2"
      },
      "metadata": {
        "created_at": "DATE",
        "author": "AUTEUR"
      },
      "analysis": {
        "llm_summary": "R√©sum√© concis g√©n√©r√© par LLM",
        "llm_keywords": ["MOT1", "MOT2"],
        "llm_entities": {
          "people": ["PERSONNE1", "PERSONNE2"],
          "organizations": ["ORG1", "ORG2"]
        },
        "llm_sentiment": "positive"
      },
      "relationships": {
        "confluence_links": [],
        "jira_tickets": []
      }
    }
  ],
  "metadata": {
    "source_file": "fichier_source.json",
    "processed_at": "DATE_TRAITEMENT",
    "llm_enrichment": {
      "model": "gpt-4",
      "enrichment_date": "DATE_ENRICHISSEMENT"
    }
  }
}
```

## üîí S√©curit√©

### Bonnes pratiques de s√©curit√©

Ce projet inclut des mesures de protection pour √©viter la fuite de donn√©es sensibles :

#### üö´ Ne jamais commiter de donn√©es sensibles
- **Cl√©s API** (AWS, OpenAI, etc.)
- **Informations personnelles** (emails, noms, etc.)
- **Donn√©es de test r√©elles**
- **Tokens d'authentification**
- **Identifiants de connexion**

#### ‚úÖ Manipulation des donn√©es sensibles
1. **Variables d'environnement** : Toujours stocker les cl√©s API dans le fichier `.env` (jamais dans le code)
2. **Donn√©es de test** : Utiliser uniquement des donn√©es synth√©tiques ou anonymis√©es
3. **Protection du Git** : Un hook pre-commit d√©tecte automatiquement les fuites potentielles

#### üßπ Nettoyage des donn√©es sensibles
Le projet inclut un outil pour nettoyer les fichiers de test :

```bash
# Nettoyer un fichier sp√©cifique
python -m tools.clean_sensitive_data path/to/file.json

# Nettoyer un dossier
python -m tools.clean_sensitive_data path/to/directory --output path/to/output
```

#### üö® En cas de fuite
1. **√âliminer** la donn√©e sensible de l'historique Git
   ```bash
   git filter-branch --force --index-filter "git rm --cached --ignore-unmatch path/to/file" --prune-empty --tag-name-filter cat -- --all
   git push origin --force
   ```
2. **Invalider** les cl√©s ou tokens compromis
3. **Informer** les personnes concern√©es

Pour plus de d√©tails, consultez le fichier [SECURITY.md](SECURITY.md).

## ‚ö†Ô∏è D√©pendances

- Python 3.8+
- typer, rich, inquirer, python-dotenv, ijson
- openai (optionnel, pour les fonctionnalit√©s LLM)
- outlines==0.2.3 (optionnel, pour l'extraction structur√©e)

## üìú Licence

Ce projet est distribu√© sous licence MIT.

<style>
.command-box {
  background-color: #f6f8fa;
  border-left: 4px solid #58a6ff;
  padding: 10px 15px;
  margin: 20px 0;
  border-radius: 3px;
}

.command-box h3 {
  margin-top: 0;
}
</style> 